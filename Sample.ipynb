{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbbcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc9fd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (822010, 2)\n",
      "\n",
      "Column names: ['url', 'status']\n",
      "\n",
      "First few rows:\n",
      "                                       url  status\n",
      "0  0000111servicehelpdesk.godaddysites.com       0\n",
      "1     000011accesswebform.godaddysites.com       0\n",
      "2                             00003.online       0\n",
      "3      0009servicedeskowa.godaddysites.com       0\n",
      "4                     000n38p.wcomhost.com       0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/new_data_urls.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0759589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url       0\n",
       "status    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398fd0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    427028\n",
       "0    394982\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f601f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    51.949246\n",
       "0    48.050754\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cb18c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(13968)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5395d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808042, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['url'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db24ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled dataset shape: (100000, 2)\n",
      "Sampled class distribution:\n",
      "status\n",
      "1    52690\n",
      "0    47310\n",
      "Name: count, dtype: int64\n",
      "Sampled class distribution:\n",
      "status\n",
      "1    52.847253\n",
      "0    47.152747\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(n=100000, random_state=42)\n",
    "print(f\"\\nSampled dataset shape: {df_sample.shape}\")\n",
    "print(f\"Sampled class distribution:\\n{df_sample['status'].value_counts()}\")\n",
    "print(f\"Sampled class distribution:\\n{df['status'].value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cce649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from URLs...\n",
      "  Processed 0/100000 URLs...\n",
      "  Processed 10000/100000 URLs...\n",
      "  Processed 20000/100000 URLs...\n",
      "  Processed 30000/100000 URLs...\n",
      "  Processed 40000/100000 URLs...\n",
      "  Processed 50000/100000 URLs...\n",
      "  Processed 60000/100000 URLs...\n",
      "  Processed 70000/100000 URLs...\n",
      "  Processed 80000/100000 URLs...\n",
      "  Processed 90000/100000 URLs...\n",
      "\n",
      "Feature shape: (100000, 26)\n",
      "\n",
      "Extracted features:\n",
      "['url_length', 'domain_length', 'num_dots', 'num_hyphens', 'num_underscores', 'num_slashes', 'num_question_marks', 'num_equals', 'num_at_symbols', 'num_ampersands', 'num_digits', 'num_special_chars', 'num_percent', 'num_sensitive', 'has_https', 'has_http', 'has_www', 'has_ip_address', 'has_double_slash', 'num_subdomains', 'letter_ratio', 'entropy', 'path_length', 'num_path_tokens', 'digit_ratio', 'special_char_ratio']\n",
      "\n",
      "Feature statistics:\n",
      "          url_length  domain_length      num_dots    num_hyphens  \\\n",
      "count  100000.000000   100000.00000  100000.00000  100000.000000   \n",
      "mean       46.996610       18.78005       2.12971       0.997760   \n",
      "std        41.067813       11.79120       1.50997       2.198714   \n",
      "min         2.000000        0.00000       0.00000       0.000000   \n",
      "25%        26.000000       13.00000       1.00000       0.000000   \n",
      "50%        37.000000       16.00000       2.00000       0.000000   \n",
      "75%        55.000000       22.00000       2.00000       1.000000   \n",
      "max      1386.000000      243.00000      36.00000      40.000000   \n",
      "\n",
      "       num_underscores    num_slashes  num_question_marks     num_equals  \\\n",
      "count    100000.000000  100000.000000       100000.000000  100000.000000   \n",
      "mean          0.292190       2.485730            0.127450       0.214200   \n",
      "std           1.066886       1.840655            0.374417       0.834197   \n",
      "min           0.000000       0.000000            0.000000       0.000000   \n",
      "25%           0.000000       1.000000            0.000000       0.000000   \n",
      "50%           0.000000       2.000000            0.000000       0.000000   \n",
      "75%           0.000000       3.000000            0.000000       0.000000   \n",
      "max          32.000000      27.000000           16.000000      20.000000   \n",
      "\n",
      "       num_at_symbols  num_ampersands  ...        has_www  has_ip_address  \\\n",
      "count   100000.000000   100000.000000  ...  100000.000000   100000.000000   \n",
      "mean         0.005570        0.104600  ...       0.135030        0.140170   \n",
      "std          0.077968        0.731618  ...       0.341757        0.347165   \n",
      "min          0.000000        0.000000  ...       0.000000        0.000000   \n",
      "25%          0.000000        0.000000  ...       0.000000        0.000000   \n",
      "50%          0.000000        0.000000  ...       0.000000        0.000000   \n",
      "75%          0.000000        0.000000  ...       0.000000        0.000000   \n",
      "max          4.000000       19.000000  ...       1.000000        1.000000   \n",
      "\n",
      "       has_double_slash  num_subdomains   letter_ratio        entropy  \\\n",
      "count      100000.00000   100000.000000  100000.000000  100000.000000   \n",
      "mean            0.00098        0.696030       0.789385       4.078685   \n",
      "std             0.03129        1.106628       0.112236       0.443024   \n",
      "min             0.00000       -1.000000       0.000000       1.000000   \n",
      "25%             0.00000        0.000000       0.741935       3.825252   \n",
      "50%             0.00000        0.000000       0.809524       4.090234   \n",
      "75%             0.00000        1.000000       0.863636       4.355018   \n",
      "max             1.00000       33.000000       1.000000       7.427747   \n",
      "\n",
      "         path_length  num_path_tokens    digit_ratio  special_char_ratio  \n",
      "count  100000.000000    100000.000000  100000.000000       100000.000000  \n",
      "mean       25.478550         1.839280       0.061142            0.149472  \n",
      "std        39.267829         1.829602       0.102096            0.050235  \n",
      "min         0.000000         0.000000       0.000000            0.000000  \n",
      "25%         0.000000         0.000000       0.000000            0.116071  \n",
      "50%        16.000000         2.000000       0.000000            0.145455  \n",
      "75%        34.000000         3.000000       0.093750            0.180723  \n",
      "max      1363.000000        25.000000       0.833333            0.473118  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "\n",
      "NaN values in features: 0\n",
      "Infinite values in features: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_url_features(url):\n",
    "    features = {}\n",
    "    \n",
    "    # Basic length features\n",
    "    features['url_length'] = len(url)\n",
    "    \n",
    "    # Extract domain\n",
    "    url_parts = url.split('/')\n",
    "    if url.startswith(('http://', 'https://')):\n",
    "        domain = url_parts[2] if len(url_parts) > 2 else ''\n",
    "    else:\n",
    "        domain = url_parts[0] if len(url_parts) > 0 else ''\n",
    "    \n",
    "    features['domain_length'] = len(domain)\n",
    "    \n",
    "    # Character composition\n",
    "    features['num_dots'] = url.count('.')\n",
    "    features['num_hyphens'] = url.count('-')\n",
    "    features['num_underscores'] = url.count('_')\n",
    "    features['num_slashes'] = url.count('/')\n",
    "    features['num_question_marks'] = url.count('?')\n",
    "    features['num_equals'] = url.count('=')\n",
    "    features['num_at_symbols'] = url.count('@')\n",
    "    features['num_ampersands'] = url.count('&')\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_special_chars'] = sum(not c.isalnum() for c in url)\n",
    "    features['num_percent'] = url.count('%')\n",
    "    sensitive_keywords = ['login', 'secure', 'account', 'bank', 'paypal', 'update', 'verify', 'password', 'sign', 'free']\n",
    "    features['num_sensitive'] = sum(1 for kw in sensitive_keywords if kw in url.lower())\n",
    "    \n",
    "    # Protocol and structure\n",
    "    features['has_https'] = int(url.startswith('https://'))\n",
    "    features['has_http'] = int(url.startswith('http://'))\n",
    "    features['has_www'] = int('www.' in url)\n",
    "    features['has_ip_address'] = int(any(char.isdigit() for char in domain))\n",
    "    \n",
    "    # Suspicious patterns\n",
    "    features['has_double_slash'] = int('//' in url[8:]) if url.startswith(('http://', 'https://')) else 0\n",
    "    features['num_subdomains'] = domain.count('.') - 1 if domain else 0\n",
    "    letters = sum(c.isalpha() for c in url)\n",
    "    features['letter_ratio'] = letters / max(len(url), 1)\n",
    "    \n",
    "    # Entropy (measure of randomness)\n",
    "    from collections import Counter\n",
    "    if len(url) > 0:\n",
    "        prob = [float(url.count(c)) / len(url) for c in dict(Counter(url))]\n",
    "        features['entropy'] = -sum([p * np.log2(p) for p in prob])\n",
    "    else:\n",
    "        features['entropy'] = 0\n",
    "    \n",
    "    # Path features\n",
    "    if url.startswith(('http://', 'https://')):\n",
    "        path = '/'.join(url_parts[3:]) if len(url_parts) > 3 else ''\n",
    "    else:\n",
    "        path = '/'.join(url_parts[1:]) if len(url_parts) > 1 else ''\n",
    "    \n",
    "    features['path_length'] = len(path)\n",
    "    features['num_path_tokens'] = len(path.split('/')) if path else 0\n",
    "    \n",
    "    # Ratio features\n",
    "    features['digit_ratio'] = features['num_digits'] / len(url) if len(url) > 0 else 0\n",
    "    features['special_char_ratio'] = features['num_special_chars'] / len(url) if len(url) > 0 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Extracting features from URLs...\")\n",
    "features_list = []\n",
    "for idx, url in enumerate(df_sample['url']):\n",
    "    if idx % 10000 == 0:\n",
    "        print(f\"  Processed {idx}/{len(df_sample)} URLs...\")\n",
    "    features_list.append(extract_url_features(url))\n",
    "\n",
    "#feature DataFrame\n",
    "X = pd.DataFrame(features_list)\n",
    "y = df_sample['status'].values\n",
    "\n",
    "print(f\"\\nFeature shape: {X.shape}\")\n",
    "print(f\"\\nExtracted features:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Check NaN/infinite values\n",
    "print(f\"\\nNaN values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Infinite values in features: {np.isinf(X).sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d962bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e3d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (80000, 26)\n",
      "Test set shape: (20000, 26)\n",
      "\n",
      "Training set class distribution:\n",
      "1    42152\n",
      "0    37848\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      "1    10538\n",
      "0     9462\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1027567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled training features: -0.000000\n",
      "Std of scaled training features: 1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Mean of scaled training features: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Std of scaled training features: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b556a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Standard Random Forest training completed\n",
      "\n",
      "Standard Random Forest CV Scores:\n",
      "  F1 Scores: [0.93093826 0.93131092 0.92640092 0.9290136  0.92942666]\n",
      "  Mean F1: 0.9294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "rf_grid = GridSearchCV(rf_base, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "print(\"Best RF Params:\", rf_grid.best_params_)\n",
    "\n",
    "print(\"Standard Random Forest training completed\")\n",
    "print(\"\\nStandard Random Forest CV Scores:\")\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=cv, scoring='f1', n_jobs=-1)\n",
    "print(f\"  F1 Scores: {rf_cv_scores}\")\n",
    "print(f\"  Mean F1: {rf_cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08a04790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, \n",
    "                             auc, precision_recall_curve, average_precision_score,\n",
    "                             roc_auc_score, f1_score, precision_score, recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e111a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba, model_name):\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': (y_pred == y_true).mean(),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba),\n",
    "        'AP-Score': average_precision_score(y_true, y_pred_proba)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63856c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'Random Forest',\n",
       " 'Accuracy': np.float64(0.92285),\n",
       " 'Precision': 0.905143680749482,\n",
       " 'Recall': 0.9535016132093377,\n",
       " 'F1-Score': 0.9286935625491012,\n",
       " 'ROC-AUC': 0.9760281800053345,\n",
       " 'AP-Score': 0.9752226242836735}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "rf_metrics = calculate_metrics(y_test, rf_pred, rf_pred_proba, 'Random Forest')\n",
    "rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb8c452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Balanced Random Forest...\n",
      "Best BRF Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Balanced Random Forest CV Scores:\n",
      "  F1 Scores: [0.92805544 0.92887176 0.92641653 0.92829128 0.92759364]\n",
      "  Mean F1: 0.9278\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "print(\"\\nTuning Balanced Random Forest...\")\n",
    "brf_base = BalancedRandomForestClassifier(random_state=42, n_jobs=-1, sampling_strategy='auto', replacement=True)\n",
    "brf_grid = GridSearchCV(brf_base, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "brf_grid.fit(X_train_scaled, y_train)\n",
    "brf_model = brf_grid.best_estimator_\n",
    "print(\"Best BRF Params:\", brf_grid.best_params_)\n",
    "\n",
    "print(\"\\nBalanced Random Forest CV Scores:\")\n",
    "brf_cv_scores = cross_val_score(brf_model, X_train_scaled, y_train, cv=cv, scoring='f1', n_jobs=-1)\n",
    "print(f\"  F1 Scores: {brf_cv_scores}\")\n",
    "print(f\"  Mean F1: {brf_cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bdec865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'Balanced RF',\n",
       " 'Accuracy': np.float64(0.9218),\n",
       " 'Precision': 0.9130915116921378,\n",
       " 'Recall': 0.9411653065097741,\n",
       " 'F1-Score': 0.9269158878504673,\n",
       " 'ROC-AUC': 0.9753031213666085,\n",
       " 'AP-Score': 0.974285801312025}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_pred = brf_model.predict(X_test_scaled)\n",
    "brf_pred_proba = brf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "brf_metrics = calculate_metrics(y_test, brf_pred, brf_pred_proba, 'Balanced RF')\n",
    "brf_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bee1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison (Test Set):\n",
      "        Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC  AP-Score\n",
      "Random Forest   0.92285   0.905144 0.953502  0.928694 0.976028  0.975223\n",
      "  Balanced RF   0.92180   0.913092 0.941165  0.926916 0.975303  0.974286\n",
      "\n",
      "================================================================================\n",
      "STANDARD RANDOM FOREST - Classification Report\n",
      "================================================================================\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Phishing (0)       0.94      0.89      0.92      9462\n",
      "Legitimate (1)       0.91      0.95      0.93     10538\n",
      "\n",
      "      accuracy                           0.92     20000\n",
      "     macro avg       0.93      0.92      0.92     20000\n",
      "  weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BALANCED RANDOM FOREST - Classification Report\n",
      "================================================================================\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Phishing (0)       0.93      0.90      0.92      9462\n",
      "Legitimate (1)       0.91      0.94      0.93     10538\n",
      "\n",
      "      accuracy                           0.92     20000\n",
      "     macro avg       0.92      0.92      0.92     20000\n",
      "  weighted avg       0.92      0.92      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([rf_metrics, brf_metrics])\n",
    "print(\"\\nModel Comparison (Test Set):\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Detailed classification reports\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STANDARD RANDOM FOREST - Classification Report\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, rf_pred, \n",
    "                          target_names=['Phishing (0)', 'Legitimate (1)']))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BALANCED RANDOM FOREST - Classification Report\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, brf_pred, \n",
    "                          target_names=['Phishing (0)', 'Legitimate (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95993020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class imbalance ratio: 0.90\n",
      "This will be used for scale_pos_weight parameter\n",
      "\n",
      "Tuning XGBoost with GridSearchCV...\n",
      "Training XGBoost (this may take 10-20 minutes)...\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [17:31:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " XGBoost training completed!\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.9}\n",
      "Best CV F1-Score: 0.9321\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: {scale_pos_weight:.2f}\")\n",
    "print(f\"This will be used for scale_pos_weight parameter\\n\")\n",
    "\n",
    "print(\"Tuning XGBoost with GridSearchCV...\")\n",
    "\n",
    "# XGBoost parameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Reduced grid for faster computation\n",
    "xgb_param_grid_reduced = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [6, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'gamma': [0, 0.1]\n",
    "}\n",
    "\n",
    "# XGBoost base model\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle imbalance\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# GridSearch\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=xgb_param_grid_reduced,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost (this may take 10-20 minutes)...\")\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "\n",
    "print(\"\\n XGBoost training completed!\")\n",
    "print(f\"Best Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"Best CV F1-Score: {xgb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6dfb2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[EVALUATION] XGBOOST PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "XGBoost Metrics:\n",
      "  Accuracy: 0.9283\n",
      "  Precision: 0.9195\n",
      "  Recall: 0.9468\n",
      "  F1-Score: 0.9329\n",
      "  ROC-AUC: 0.9788\n",
      "  AP-Score: 0.9786\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "XGBoost Cross-Validation Scores:\n",
      "--------------------------------------------------------------------------------\n",
      "F1 Scores: [0.93305219 0.93338773 0.93110866 0.93158048 0.93270572]\n",
      "Mean F1: 0.9324 \n",
      "\n",
      "================================================================================\n",
      "XGBOOST - Classification Report\n",
      "================================================================================\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Phishing (0)       0.94      0.91      0.92      9462\n",
      "Legitimate (1)       0.92      0.95      0.93     10538\n",
      "\n",
      "      accuracy                           0.93     20000\n",
      "     macro avg       0.93      0.93      0.93     20000\n",
      "  weighted avg       0.93      0.93      0.93     20000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8588  874]\n",
      " [ 561 9977]]\n",
      "\n",
      "True Negatives (Phishing correctly identified): 8588\n",
      "False Positives (Legitimate marked as Phishing): 874\n",
      "False Negatives (Phishing marked as Legitimate): 561\n",
      "True Positives (Legitimate correctly identified): 9977\n"
     ]
    }
   ],
   "source": [
    "xgb_model_final = xgb_grid\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[EVALUATION] XGBOOST PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Predictions\n",
    "xgb_pred = xgb_model_final.predict(X_test_scaled)\n",
    "xgb_pred_proba = xgb_model_final.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "xgb_metrics = calculate_metrics(y_test, xgb_pred, xgb_pred_proba, 'XGBoost')\n",
    "\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "for key, value in xgb_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"XGBoost Cross-Validation Scores:\")\n",
    "print(\"-\" * 80)\n",
    "xgb_cv_scores = cross_val_score(\n",
    "    xgb_model_final, X_train_scaled, y_train, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1', n_jobs=-1\n",
    ")\n",
    "print(f\"F1 Scores: {xgb_cv_scores}\")\n",
    "print(f\"Mean F1: {xgb_cv_scores.mean():.4f} \")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"XGBOOST - Classification Report\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, xgb_pred, \n",
    "                          target_names=['Phishing (0)', 'Legitimate (1)']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_xgb = confusion_matrix(y_test, xgb_pred)\n",
    "print(cm_xgb)\n",
    "print(f\"\\nTrue Negatives (Phishing correctly identified): {cm_xgb[0,0]}\")\n",
    "print(f\"False Positives (Legitimate marked as Phishing): {cm_xgb[0,1]}\")\n",
    "print(f\"False Negatives (Phishing marked as Legitimate): {cm_xgb[1,0]}\")\n",
    "print(f\"True Positives (Legitimate correctly identified): {cm_xgb[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7585f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FINAL MODEL COMPARISON - ALL CLASSIFIERS\n",
      "================================================================================\n",
      "\n",
      "Complete Performance Comparison:\n",
      "        Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC  AP-Score\n",
      "Random Forest   0.92285   0.905144 0.953502  0.928694 0.976028  0.975223\n",
      "  Balanced RF   0.92180   0.913092 0.941165  0.926916 0.975303  0.974286\n",
      "      XGBoost   0.92825   0.919454 0.946764  0.932909 0.978774  0.978607\n",
      "\n",
      "================================================================================\n",
      "BEST PERFORMING MODEL: XGBoost\n",
      "================================================================================\n",
      "  • Accuracy:  0.9283 (92.83%)\n",
      "  • Precision: 0.9195\n",
      "  • Recall:    0.9468\n",
      "  • F1-Score:  0.9329\n",
      "  • ROC-AUC:   0.9788\n",
      "  • AP-Score:  0.9786\n"
     ]
    }
   ],
   "source": [
    "# ========== COMPREHENSIVE MODEL COMPARISON ==========\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FINAL MODEL COMPARISON - ALL CLASSIFIERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Update comparison dataframe\n",
    "all_models_comparison = pd.DataFrame([\n",
    "    rf_metrics, \n",
    "    brf_metrics,\n",
    "    xgb_metrics\n",
    "])\n",
    "\n",
    "print(\"\\nComplete Performance Comparison:\")\n",
    "print(all_models_comparison.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_idx = all_models_comparison['F1-Score'].idxmax()\n",
    "best_model_name = all_models_comparison.loc[best_idx, 'Model']\n",
    "best_accuracy = all_models_comparison.loc[best_idx, 'Accuracy']\n",
    "best_f1 = all_models_comparison.loc[best_idx, 'F1-Score']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"BEST PERFORMING MODEL: {best_model_name}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  • Accuracy:  {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"  • Precision: {all_models_comparison.loc[best_idx, 'Precision']:.4f}\")\n",
    "print(f\"  • Recall:    {all_models_comparison.loc[best_idx, 'Recall']:.4f}\")\n",
    "print(f\"  • F1-Score:  {best_f1:.4f}\")\n",
    "print(f\"  • ROC-AUC:   {all_models_comparison.loc[best_idx, 'ROC-AUC']:.4f}\")\n",
    "print(f\"  • AP-Score:  {all_models_comparison.loc[best_idx, 'AP-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb0435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
